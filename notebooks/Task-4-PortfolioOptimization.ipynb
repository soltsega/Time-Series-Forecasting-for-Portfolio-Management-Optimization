{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Task 4: Portfolio Optimization\n",
                "\n",
                "In this task, we optimize a portfolio of **TSLA**, **BND**, and **SPY** using **Modern Portfolio Theory (MPT)**. \n",
                "We use the TSLA forecast from Task 3 and historical data for bonds and the broad market. \n",
                "Optimization is performed using `scipy.optimize`."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 1: Prepare Expected Returns & Covariance\n",
                "\n",
                "- **Mu (Expected Returns):** TSLA (Forecast), BND & SPY (Historical Annualized).\n",
                "- **Sigma (Covariance):** Historical covariance matrix."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import os\n",
                "import pmdarima as pm\n",
                "from scipy.optimize import minimize\n",
                "from IPython.display import display, Markdown\n",
                "\n",
                "# 1. Load historical data\n",
                "data_path = \"../data/processed\"\n",
                "assets = [\"TSLA\", \"BND\", \"SPY\"]\n",
                "dfs = {asset: pd.read_csv(os.path.join(data_path, f\"{asset}_final_processed.csv\"), index_col='Date', parse_dates=True) for asset in assets}\n",
                "\n",
                "# 2. Calculate Expected Returns\n",
                "tsla_hist = dfs['TSLA']['Close']\n",
                "model_future = pm.auto_arima(tsla_hist, seasonal=False, error_action='ignore', suppress_warnings=True)\n",
                "future_forecast = model_future.predict(n_periods=252)\n",
                "\n",
                "last_price = tsla_hist.iloc[-1]\n",
                "expected_price = future_forecast.iloc[-1]\n",
                "tsla_expected_return = (expected_price / last_price) - 1\n",
                "\n",
                "expected_returns = pd.Series(index=assets, dtype=float)\n",
                "expected_returns['TSLA'] = tsla_expected_return\n",
                "\n",
                "# Historical stats for others\n",
                "prices = pd.concat({ticker: df['Close'] for ticker, df in dfs.items()}, axis=1)\n",
                "prices = prices.ffill().dropna()\n",
                "daily_returns = prices.pct_change().dropna()\n",
                "\n",
                "for asset in [\"BND\", \"SPY\"]:\n",
                "    avg_daily = daily_returns[asset].mean()\n",
                "    expected_returns[asset] = (1 + avg_daily)**252 - 1\n",
                "\n",
                "mu = expected_returns.values\n",
                "cov_matrix = daily_returns.cov() * 252 # Annualized Covariance\n",
                "\n",
                "print(\"--- Expected Returns (Annualized) ---\")\n",
                "print(expected_returns)\n",
                "print(\"\\n--- Covariance Matrix (Annualized) ---\")\n",
                "print(cov_matrix)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 2: Define Optimization Logic (Scipy)\n",
                "\n",
                "We define the objective functions for: \n",
                "1. **Maximize Sharpe Ratio** (minimize negative sharpe)\n",
                "2. **Minimize Volatility**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def get_ret_vol_sr(weights, mu, cov_matrix):\n",
                "    weights = np.array(weights)\n",
                "    ret = np.sum(weights * mu)\n",
                "    vol = np.sqrt(np.dot(weights.T, np.dot(cov_matrix, weights)))\n",
                "    sr = ret / vol\n",
                "    return np.array([ret, vol, sr])\n",
                "\n",
                "def neg_sharpe(weights, mu, cov_matrix):\n",
                "    return -get_ret_vol_sr(weights, mu, cov_matrix)[2]\n",
                "\n",
                "def minimize_volatility(weights, mu, cov_matrix):\n",
                "    return get_ret_vol_sr(weights, mu, cov_matrix)[1]\n",
                "\n",
                "# Constraints and Bounds\n",
                "num_assets = len(assets)\n",
                "bounds = tuple((0, 1) for _ in range(num_assets))\n",
                "constraints = ({'type': 'eq', 'fun': lambda x: np.sum(x) - 1})\n",
                "init_guess = num_assets * [1. / num_assets,]"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 3: Run Optimization"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 1. Max Sharpe Ratio\n",
                "opt_sharpe = minimize(neg_sharpe, init_guess, args=(mu, cov_matrix), method='SLSQP', bounds=bounds, constraints=constraints)\n",
                "w_max_sharpe = opt_sharpe.x\n",
                "perf_max_sharpe = get_ret_vol_sr(w_max_sharpe, mu, cov_matrix)\n",
                "\n",
                "# 2. Min Volatility\n",
                "opt_vol = minimize(minimize_volatility, init_guess, args=(mu, cov_matrix), method='SLSQP', bounds=bounds, constraints=constraints)\n",
                "w_min_vol = opt_vol.x\n",
                "perf_min_vol = get_ret_vol_sr(w_min_vol, mu, cov_matrix)\n",
                "\n",
                "print(\"Max Sharpe Weights:\", dict(zip(assets, np.round(w_max_sharpe, 4))))\n",
                "print(\"Min Vol Weights:\", dict(zip(assets, np.round(w_min_vol, 4))))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 4: Visualize Efficient Frontier"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Generate Efficient Frontier Points\n",
                "frontier_y = np.linspace(perf_min_vol[0], perf_max_sharpe[0] * 1.05, 100)\n",
                "frontier_x = []\n",
                "\n",
                "for possible_return in frontier_y:\n",
                "    cons = ({'type': 'eq', 'fun': lambda x: np.sum(x) - 1},\n",
                "            {'type': 'eq', 'fun': lambda x: get_ret_vol_sr(x, mu, cov_matrix)[0] - possible_return})\n",
                "    \n",
                "    result = minimize(minimize_volatility, init_guess, args=(mu, cov_matrix), method='SLSQP', bounds=bounds, constraints=cons)\n",
                "    frontier_x.append(result.fun)\n",
                "\n",
                "plt.figure(figsize=(10, 6))\n",
                "plt.plot(frontier_x, frontier_y, 'k--', linewidth=3, label='Efficient Frontier')\n",
                "\n",
                "# Random Portfolios for Context\n",
                "np.random.seed(42)\n",
                "all_weights = np.zeros((5000, len(assets)))\n",
                "ret_arr = np.zeros(5000)\n",
                "vol_arr = np.zeros(5000)\n",
                "sharpe_arr = np.zeros(5000)\n",
                "\n",
                "for i in range(5000):\n",
                "    w = np.array(np.random.random(len(assets)))\n",
                "    w = w / np.sum(w)\n",
                "    all_weights[i,:] = w\n",
                "    r, v, s = get_ret_vol_sr(w, mu, cov_matrix)\n",
                "    ret_arr[i] = r\n",
                "    vol_arr[i] = v\n",
                "    sharpe_arr[i] = s\n",
                "\n",
                "plt.scatter(vol_arr, ret_arr, c=sharpe_arr, cmap='viridis', alpha=0.3)\n",
                "plt.colorbar(label='Sharpe Ratio')\n",
                "\n",
                "# Mark Optimal Portfolios\n",
                "plt.scatter(perf_max_sharpe[1], perf_max_sharpe[0], c='red', s=200, marker='*', label='Max Sharpe')\n",
                "plt.scatter(perf_min_vol[1], perf_min_vol[0], c='blue', s=200, marker='*', label='Min Volatility')\n",
                "\n",
                "plt.xlabel('Volatility (Std. Dev)')\n",
                "plt.ylabel('Expected Returns')\n",
                "plt.title('Efficient Frontier (Scipy Optimized)')\n",
                "plt.legend()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 5: Final Recommendation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Formatting results\n",
                "w_dict = dict(zip(assets, w_max_sharpe))\n",
                "\n",
                "report = f\"\"\"\n",
                "### Final Portfolio Recommendation\n",
                "Based on the **Scipy SLSQP Optimization**, we recommend the **Maximum Sharpe Ratio Portfolio**.\n",
                "\n",
                "#### **Optimal Weights**\n",
                "- **TSLA:** {w_dict['TSLA']:.2%}\n",
                "- **BND:** {w_dict['BND']:.2%}\n",
                "- **SPY:** {w_dict['SPY']:.2%}\n",
                "\n",
                "#### **Expected Performance Metrics**\n",
                "- **Expected Annual Return:** {perf_max_sharpe[0]:.2%}\n",
                "- **Annual Volatility:** {perf_max_sharpe[1]:.2%}\n",
                "- **Sharpe Ratio:** {perf_max_sharpe[2]:.2f}\n",
                "\n",
                "### **Rationale**\n",
                "1. **Optimization Method:** Due to environment constraints with `cvxpy`, we utilized `scipy.optimize.minimize` with the SLSQP solver to successfully map the efficient frontier and locate the tangency portfolio.\n",
                "2. **Allocation Logic:** The algorithm allocates capital to maximize the risk-adjusted return (Sharpe). Given TSLA's low forecasted return (~0%) but high volatility, the optimizer is expected to favor SPY (growth) and BND (stability) heavily.\n",
                "3. **Conclusion:** This portfolio provides the statistically optimal mix for the given input assumptions.\n",
                "\"\"\"\n",
                "\n",
                "display(Markdown(report))"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.14.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}